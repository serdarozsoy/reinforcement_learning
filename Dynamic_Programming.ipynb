{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dynamic Programming.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "xGmg-6ZP3LhY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dynamic Programming\n",
        "\n",
        "\n",
        "Video link: https://www.youtube.com/watch?v=DiAtV7SneRE\n",
        "\n",
        "\n",
        "## Demo - Aligning DNA Sequences visually using Dynamic programming\n",
        "\n",
        "Working demo at: https://valiec.github.io/AlignmentVisualizer\n",
        "\n",
        "\n",
        "## What is Dynamic Programming?\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/2000/1*7QbvB25maQRxi7LGYOAfYw.png  \"Logo Title Text 1\")\n",
        "\n",
        "### \"Dynamic programming amounts to breaking down an optimization problem into simpler sub-problems, and storing the solution to each sub-problem so that each sub-problem is only solved once\" - Bellman \n",
        "\n",
        "![alt text](https://www.cs.utah.edu/~draperg/cartoons/dynamic.png  \"Logo Title Text 1\")\n",
        "\n",
        "- Can be used to solve many problems in time O(n^2) or O(n^3) for which a naive approach would take exponential time\n",
        "- Similar to  “divide-and-conquer” as a general method (mergesort, quicksort), except that unlike divide-and-conquer, the subproblems will typically overlap.\n",
        "\n",
        "Basic idea: \n",
        "\n",
        "- Break a problem up into subproblems\n",
        "- Use Optimal Solutions to subproblems to give us optimal solutions to the larger ones\n",
        "- Its OK if our problems overlap, as long as there are not too many of them \n",
        "\n",
        "- Dynamic programming is basically, recursion plus using common sense. What it means is that recursion allows you to express the value of a function in terms of other values of that function. Where the common sense tells you that if you implement your function in a way that the recursive calls are done in advance, and stored for easy access, it will make your program faster. \n",
        "- Trade space for time, i.e. to say that instead of calculating all the states taking a lot of time but no space, we take up space to store the results of all the sub-problems to save time later.\n",
        "\n",
        "## When to use Dynamic Programming?\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*KzOeC7Z0rVPbZhln1VwrHw.png  \"Logo Title Text 1\")\n",
        "\n",
        "Every Dynamic Programming problem has 4 steps:\n",
        "\n",
        "- Show that the problem can be broken down into optimal sub-problems.\n",
        "- Recursively define the value of the solution by expressing it in terms of optimal solutions for smaller sub-problems.\n",
        "- Compute the value of the optimal solution in bottom-up fashion.\n",
        "- Construct an optimal solution from the computed information.\n",
        "\n",
        "![alt text](http://eundi.weebly.com/uploads/4/3/9/3/43934131/8147629.png?737  \"Logo Title Text 1\")\n",
        "\n",
        "There are two key attributes that a problem must have in order for DP to be applicable: optimal structure and overlapping subproblems:\n",
        "\n",
        "![alt text](http://slideplayer.com/slide/7767405/25/images/72/Dynamic+programming:+Summary.jpg  \"Logo Title Text 1\")\n",
        "\n",
        "- When you have an optimal structure, then the optimal solution of a given problem can be obtained by the combination of optimal solutions of its subproblems\n",
        "- when you have overlapping subproblems then a solution of a problem should require the same subproblem again and again\n",
        "\n",
        "Hey, please note that if a problem can be solved by combining optimal solution of non overlapping subproblems then we are in the “divide and conquer” area, where for example merge sort and quick sort lies.\n",
        "\n",
        "## Tabulation (bottom-up) vs Memoization (top-down)\n",
        "\n",
        "- Bottom Up (Tabulation) - I'm going to learn programming. Then, I will start practicing. Then, I will start taking part in contests. Then, I'll practice even more and try to improve. After working hard like crazy, I'll be an amazing coder.\n",
        "\n",
        "- Top Down (Memoization) - I will be an amazing coder. How? I will work hard like crazy. How? I'll practice more and try to improve. How? I'll start taking part in contests. Then? I'll practicing. How? I'm going to learn programming.\n",
        "\n",
        "![alt text](https://www.geeksforgeeks.org/wp-content/uploads/Tabulation-vs-Memoization-1.png  \"Logo Title Text 1\")\n",
        "\n",
        "### Overlapping subproblems \n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/1200/1*bfSmmMFLEaeDEHtQo0Ca_w.jpeg  \"Logo Title Text 1\")\n",
        "\n",
        "#### Example -  Fibonacci Sequence\n",
        "\n",
        "![alt text](https://i.imgur.com/NqrARtv.png  \"Logo Title Text 1\")\n",
        "\n",
        "```python\n",
        " /* simple recursive program for Fibonacci numbers */\n",
        "int fib(int n)\n",
        "{\n",
        "   if ( n <= 1 )\n",
        "      return n;\n",
        "   return fib(n-1) + fib(n-2);\n",
        "}\n",
        "```\n",
        "- The function f(3) is being called 2 times\n",
        "- If we would have stored the value of f(3), instead of computing it again, we could have reused the old stored value\n",
        "\n",
        "\n",
        "#### Lets try some memoization so that we can store the values for reusability\n",
        "\n",
        "- The memoized program for a problem is similar to the recursive version with a small modification that it looks into a lookup table before computing solutions. \n",
        "- We initialize a lookup array with all initial values as NIL. \n",
        "- Whenever we need solution to a subproblem, we first look into the lookup table. \n",
        "- If the precomputed value is there then we return that value, otherwise we calculate the value and put the result in lookup table so that it can be reused later.\n",
        "\n",
        "```python\n",
        "# Python program for Memoized version of nth Fibonacci number\n",
        "# Function to calculate nth Fibonacci number\n",
        "def fib(n, lookup):\n",
        " \n",
        "    # Base case\n",
        "    if n == 0 or n == 1 :\n",
        "        lookup[n] = n\n",
        " \n",
        "    # If the value is not calculated previously then calculate it\n",
        "    if lookup[n] is None:\n",
        "        lookup[n] = fib(n-1 , lookup)  + fib(n-2 , lookup) \n",
        " \n",
        "    # return the value corresponding to that value of n\n",
        "    return lookup[n]\n",
        "     #end of function\n",
        " \n",
        "Driver program to test the above function\n",
        "def main():\n",
        "    n = 34\n",
        "    #Declaration of lookup table\n",
        "    #Handles till n = 100 \n",
        "    lookup = [None]*(101)\n",
        "    print \"Fibonacci Number is \", fib(n, lookup)\n",
        " \n",
        "if __name__==\"__main__\":\n",
        "    main()\n",
        "\n",
        "```\n",
        "\n",
        "#### Lets try the tabulation approach now (bottom up)\n",
        "\n",
        "\n",
        "- The tabulated program for a given problem builds a table in bottom up fashion and returns the last entry from table\n",
        "- So for the same Fibonacci number, we first calculate fib(0) then fib(1) then fib(2) then fib(3) and so on. \n",
        "- Literally, we are building the solutions of subproblems bottom-up.\n",
        "\n",
        "```python\n",
        "#Python program Tabulated (bottom up) version\n",
        "def fib(n):\n",
        " \n",
        "    # array declaration\n",
        "    f = [0]*(n+1)\n",
        " \n",
        "    # base case assignment\n",
        "    f[1] = 1\n",
        " \n",
        "    # calculating the fibonacci and storing the values\n",
        "    for i in xrange(2 , n+1):\n",
        "        f[i] = f[i-1] + f[i-2]\n",
        "    return f[n]\n",
        " \n",
        "#Driver program to test the above function\n",
        "def main():\n",
        "    n = 9\n",
        "    print \"Fibonacci number is \" , fib(n)\n",
        " \n",
        "if __name__==\"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "- Both Tabulated and Memoized store the solutions of subproblems. \n",
        "- In Memoized version, table is filled on demand while in Tabulated version, starting from the first entry, all entries are filled one by one. \n",
        "- Unlike the Tabulated version, all entries of the lookup table are not necessarily filled in Memoized version. \n",
        "\n",
        "\n",
        "### Optimal Substructure\n",
        "\n",
        "- A given problems has the Optimal Substructure Property if the optimal solution of the given problem can be obtained by using the optimal solutions of its subproblems.\n",
        "-  For example, the Shortest Path problem has following optimal substructure property:\n",
        "\n",
        "## \"If a node x lies in the shortest path from a source node u to destination node v then the shortest path from u to v is combination of shortest path from u to x and shortest path from x to v\"\n",
        "\n",
        "- What do we use here? Bellman-ford  algorithm for finding the shortest path.\n",
        "- Given a graph and a source vertex src in graph, find shortest paths from src to all vertices in the given graph. The graph may contain negative weight edges.\n",
        "- Bottom up approach!\n",
        "\n",
        "- 1 First calculate the shortest distances which have at-most one edge in the path. \n",
        "- 2 Then, calculate shortest paths with at-most 2 edges, and so on. \n",
        "- 3 After the ith iteration of outer loop, the shortest paths with at most i edges are calculated. \n",
        "- 4 There can be maximum |V| – 1 edges in any simple path, that is why the outer loop runs |v| – 1 times. \n",
        "- The idea is, assuming that there is no negative weight cycle, if we have calculated the shortest paths with at most i edges, then an iteration over all edges guarantees to give shortest path with at-most (i+1) edges \n",
        "\n",
        "![alt text](https://i.ytimg.com/vi/hq3TZInZ5J4/maxresdefault.jpg  \"Logo Title Text 1\")"
      ]
    },
    {
      "metadata": {
        "id": "Z-tw5aUX3Lhb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "48ad1d20-8842-4fa4-a987-1aadb509d5e5"
      },
      "cell_type": "code",
      "source": [
        "# Python program for Bellman-Ford's single source \n",
        "# shortest path algorithm.\n",
        " \n",
        "from collections import defaultdict\n",
        " \n",
        "#Class to represent a graph\n",
        "class Graph:\n",
        " \n",
        "    def __init__(self,vertices):\n",
        "        self.V= vertices #No. of vertices\n",
        "        self.graph = [] # default dictionary to store graph\n",
        "  \n",
        "    # function to add an edge to graph\n",
        "    def addEdge(self,u,v,w):\n",
        "        self.graph.append([u, v, w])\n",
        "         \n",
        "    # utility function used to print the solution\n",
        "    def printArr(self, dist):\n",
        "        print(\"Vertex   Distance from Source\")\n",
        "        for i in range(self.V):\n",
        "            print(\"%d \\t\\t %d\" % (i, dist[i]))\n",
        "     \n",
        "    # The main function that finds shortest distances from src to\n",
        "    # all other vertices using Bellman-Ford algorithm.  The function\n",
        "    # also detects negative weight cycle\n",
        "    def BellmanFord(self, src):\n",
        " \n",
        "        # Step 1: Initialize distances from src to all other vertices\n",
        "        # as INFINITE\n",
        "        dist = [float(\"Inf\")] * self.V\n",
        "        dist[src] = 0\n",
        " \n",
        "        # Step 2: Relax all edges |V| - 1 times. A simple shortest \n",
        "        # path from src to any other vertex can have at-most |V| - 1 \n",
        "        # edges\n",
        "        for i in range(self.V - 1):\n",
        "            # Update dist value and parent index of the adjacent vertices of\n",
        "            # the picked vertex. Consider only those vertices which are still in\n",
        "            # queue\n",
        "            for u, v, w in self.graph:\n",
        "                if dist[u] != float(\"Inf\") and dist[u] + w < dist[v]:\n",
        "                        dist[v] = dist[u] + w\n",
        " \n",
        "        # Step 3: check for negative-weight cycles.  The above step \n",
        "        # guarantees shortest distances if graph doesn't contain \n",
        "        # negative weight cycle.  If we get a shorter path, then there\n",
        "        # is a cycle.\n",
        " \n",
        "        for u, v, w in self.graph:\n",
        "                if dist[u] != float(\"Inf\") and dist[u] + w < dist[v]:\n",
        "                        print (\"Graph contains negative weight cycle\")\n",
        "                        return\n",
        "                         \n",
        "        # print all distance\n",
        "        self.printArr(dist)\n",
        " \n",
        "g = Graph(5)\n",
        "g.addEdge(0, 1, -1)\n",
        "g.addEdge(0, 2, 4)\n",
        "g.addEdge(1, 2, 3)\n",
        "g.addEdge(1, 3, 2)\n",
        "g.addEdge(1, 4, 2)\n",
        "g.addEdge(3, 2, 5)\n",
        "g.addEdge(3, 1, 1)\n",
        "g.addEdge(4, 3, -3)\n",
        " \n",
        "#Print the solution\n",
        "g.BellmanFord(0)\n",
        " "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vertex   Distance from Source\n",
            "0 \t\t 0\n",
            "1 \t\t -1\n",
            "2 \t\t 2\n",
            "3 \t\t -2\n",
            "4 \t\t 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BpJ08qZb3Lhf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Applications in Artificial Intelligence\n",
        "\n",
        "### Backpropagation (supervised learning) \n",
        "\n",
        "- In principle,wecould calculate the partial derivative of the function with respect to any weight simply by tracing out the nodes “downstream” from it, and calculating the (longer) derivative chains manually. \n",
        "- We could do this for every node, although it might get a bit tedious\n",
        "- The key idea of “backpropagation” is that we can reuse results for an efficiency increase, just as we do for dynamic programming.\n",
        "\n",
        "See this: https://github.com/llSourcell/Make_a_neural_network/blob/master/demo.py\n",
        "\n",
        "### Reinforcement Learning \n",
        "\n",
        "- DP solves for the optimal policy or value function by recursion. \n",
        "- It requires knowledge of the markov decision process (MDP) or a model of the world so that the recursions can be carried out. \n",
        "- It is typically lumped under \"planning\" rather than \"learning\", in that you already know the MDP, and just need to figure out what to do (optimally).\n",
        "\n",
        "![alt text](https://camo.githubusercontent.com/9f59450ab0458e82c4d728415a4d0f1671ea8a48/68747470733a2f2f706c616e73706163652e6f72672f32303137303833302d6265726b656c65795f646565705f726c5f626f6f7463616d702f696d672f616e6e6f74617465642e6a7067  \"Logo Title Text 1\")\n",
        "\n",
        "https://github.com/higgsfield/RL-Adventure-2\n",
        "\n",
        "![alt text](https://image.slidesharecdn.com/ml-sep-09-091009141615-phpapp01/95/regretbased-reward-elicitation-for-markov-decision-processes-39-728.jpg?cb=1255098159  \"Logo Title Text 1\")\n",
        "\n",
        "## Runtime analysis\n",
        "\n",
        "Runtime takes the form\n",
        "\n",
        "### Pre-processing + Loop * Recurrence + Post-processing\n",
        "\n",
        "\n",
        "- Pre-processing\n",
        "- Loop: How many times the for loop runs\n",
        "- Recurrence: How much time it takes the recurrence to run in one for loop iteration\n",
        "- Post-processing\n"
      ]
    },
    {
      "metadata": {
        "id": "wAcqQEBsFfZ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### More learning resources:\n",
        "\n",
        "https://www.youtube.com/watch?v=W2ote4jCuYw\n",
        "\n",
        "https://www.youtube.com/watch?v=RI1Ey1LkpxQ\n",
        "\n",
        "https://www.youtube.com/watch?v=OQ5jsbhAv_M\n",
        "\n",
        "https://www.youtube.com/watch?v=cYT-JTZPpWc\n",
        "\n",
        "https://www.youtube.com/watch?v=vaGRbiTSEkQ\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}